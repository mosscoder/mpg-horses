{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve geotiff paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get survey array\n",
    "# Read the google sheet MPG Aerial Survey Manifest\n",
    "sheet = pd.read_csv(\n",
    "    \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTgk2SSxgZ76UTYOlmf5UtjF1q59ZpKXCNH1Mn3rzbxQ_f6MvoTUirnUIKdcKxd-NIZk-MN8bsG3SP6/pub?output=csv\"\n",
    ")\n",
    "\n",
    "# filter by sensors 'RGB' and site 'Upper Partridge'\n",
    "upper_partridge = sheet[(sheet.sensor == \"RGB\") & (sheet.site == \"Upper Partridge\")]\n",
    "\n",
    "# Create array of cloud_storage paths from the orthomosaic column excluding nulls\n",
    "cloud_storage_paths = upper_partridge.orthomosaic.dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download cloud_storage_paths array with wget to ../data/raster/geotiffs\n",
    "# for url in cloud_storage_paths:\n",
    "#     filename = url.split('/')[-1]\n",
    "#     os.system(f'wget -q {url} -O ../data/raster/geotiffs/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local geotiff array\n",
    "geotiffs = [f'../data/raster/geotiffs/{x}' for x in os.listdir('../data/raster/geotiffs') if not x.endswith('.DS_Store')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local ground truth file\n",
    "groundtruth = '../data/vector/groundtruth.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://colab.research.google.com/drive/15LFRMVOfEiF__FswVqTQstZC5ocC6Ur0?usp=sharing for cropping functions\n",
    "\n",
    "# Define the function that creates a bounding box and returns its min and max coordinates\n",
    "def bbox_side_len(point, side_len=10):\n",
    "    if point is None or point.is_empty:\n",
    "        return None, None, None, None  # Return None for all four values if the point is invalid\n",
    "    half_side = side_len / 2\n",
    "    minx, miny = point.x - half_side, point.y - half_side\n",
    "    maxx, maxy = point.x + half_side, point.y + half_side\n",
    "    return minx, miny, maxx, maxy\n",
    "\n",
    "def process_bbox(raster_path, bbox, output_dir, read_lock, write_lock, idx):\n",
    "    minx, miny, maxx, maxy = bbox\n",
    "    if minx is None:\n",
    "        return \"Invalid point\"\n",
    "\n",
    "    try:\n",
    "        with rio.open(raster_path) as src:\n",
    "            # Check if the bbox is within the raster bounds\n",
    "            raster_bounds = src.bounds\n",
    "            if (minx >= raster_bounds.right or maxx <= raster_bounds.left or\n",
    "                miny >= raster_bounds.top or maxy <= raster_bounds.bottom):\n",
    "                return \"Bounding box outside raster extent\"\n",
    "\n",
    "            window = src.window(minx, miny, maxx, maxy)\n",
    "\n",
    "            # Ensure the window has a valid size\n",
    "            if window.width < 1 or window.height < 1:\n",
    "                return \"Resulting window too small\"\n",
    "\n",
    "            with read_lock:\n",
    "                src_array = src.read(window=window)\n",
    "\n",
    "            # If the read array is empty, skip this bbox\n",
    "            if src_array.size == 0:\n",
    "                return \"Empty array read\"\n",
    "\n",
    "            profile = src.profile.copy()\n",
    "            profile.update({\n",
    "                \"height\": src_array.shape[1],\n",
    "                \"width\": src_array.shape[2],\n",
    "                \"transform\": rio.windows.transform(window, src.transform)\n",
    "            })\n",
    "\n",
    "            output_file = f\"{output_dir}/{idx}.tif\"  # Changed to use idx\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            with write_lock:\n",
    "                with rio.open(output_file, \"w\", **profile) as dst:\n",
    "                    dst.write(src_array)\n",
    "\n",
    "        return \"Success\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def do_tiling(raster_path, points_gdf, output_dir, num_workers=4, side_len=10):\n",
    "    # Create list of (bbox, idx) tuples\n",
    "    bbox_data = [(bbox_side_len(point, side_len=side_len), idx) \n",
    "                 for idx, point in zip(points_gdf.idx, points_gdf.geometry)]\n",
    "    valid_bbox_data = [(bbox, idx) for bbox, idx in bbox_data if bbox[0] is not None]\n",
    "\n",
    "    read_lock = threading.Lock()\n",
    "    write_lock = threading.Lock()\n",
    "\n",
    "    pbar = tqdm(total=len(valid_bbox_data), desc=\"Processing bounding boxes\", unit=\"bbox\")\n",
    "    errors = []\n",
    "\n",
    "    def process_and_update(bbox_info):\n",
    "        bbox, idx = bbox_info\n",
    "        result = process_bbox(raster_path, bbox, output_dir, read_lock, write_lock, idx)\n",
    "        pbar.update(1)\n",
    "        if result != \"Success\":\n",
    "            errors.append(result)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        list(executor.map(process_and_update, valid_bbox_data))\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nEncountered {len(errors)} errors:\")\n",
    "        for error in errors[:10]:  # Print first 10 errors\n",
    "            print(f\"  - {error}\")\n",
    "        if len(errors) > 10:\n",
    "            print(f\"  ... and {len(errors) - 10} more.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crop_sz_meters = 5 # how big to make crops in meters\n",
    "num_cores = os.cpu_count()\n",
    "print(f'Using {num_cores} cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop tiles for each geotiff\n",
    "for geotiff in geotiffs:\n",
    "    survey_name = os.path.basename(geotiff).split('.')[0].replace('-visible', '')\n",
    "    \n",
    "    # Set up output directories\n",
    "    output_base = f'../data/raster/tiles/{survey_name}'\n",
    "    for label in ['presence', 'absence']:\n",
    "        os.makedirs(f'{output_base}/{label}', exist_ok=True)\n",
    "\n",
    "    # Read and align CRS of raster and points\n",
    "    with rio.open(geotiff) as src:\n",
    "        raster_crs = src.crs\n",
    "        print(f\"Raster CRS: {raster_crs}\")\n",
    "\n",
    "    gdf = gpd.read_file(groundtruth)\n",
    "    print(f\"GeoJSON CRS: {gdf.crs}\")\n",
    "\n",
    "    if gdf.crs != raster_crs:\n",
    "        print(f\"Reprojecting from {gdf.crs} to {raster_crs}\")\n",
    "        gdf = gdf.to_crs(raster_crs)\n",
    "\n",
    "    # Process both presence and absence points\n",
    "    for presence_val in [1, 0]:\n",
    "        label = 'presence' if presence_val == 1 else 'absence'\n",
    "        points = gdf[gdf['Presence'] == presence_val]\n",
    "        output_dir = f'{output_base}/{label}'\n",
    "        \n",
    "        do_tiling(geotiff, points, output_dir,\n",
    "                 num_workers=num_cores, side_len=target_crop_sz_meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -rq ../data/raster/tiles/mpg-horses_tiles.zip ../data/raster/tiles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpg-horses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
