{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve geotiff paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get survey array\n",
    "# Read the google sheet MPG Aerial Survey Manifest\n",
    "sheet = pd.read_csv(\n",
    "    \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTgk2SSxgZ76UTYOlmf5UtjF1q59ZpKXCNH1Mn3rzbxQ_f6MvoTUirnUIKdcKxd-NIZk-MN8bsG3SP6/pub?output=csv\"\n",
    ")\n",
    "\n",
    "# filter by sensors 'RGB' and site 'Upper Partridge'\n",
    "upper_partridge = sheet[(sheet.sensor == \"RGB\") & (sheet.site == \"Upper Partridge\")]\n",
    "\n",
    "# Create array of cloud_storage paths from the orthomosaic column excluding nulls\n",
    "cloud_storage_paths = upper_partridge.orthomosaic.dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download geotiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download cloud_storage_paths array with wget to ../data/raster/geotiffs\n",
    "for url in cloud_storage_paths:\n",
    "    filename = url.split('/')[-1]\n",
    "    os.system(f'wget -q {url} -O ../data/raster/geotiffs/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local geotiff array\n",
    "geotiffs = [f'../data/raster/geotiffs/{x}' for x in os.listdir('../data/raster/geotiffs') if not x.endswith('.DS_Store')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local ground truth file\n",
    "groundtruth = '../data/vector/groundtruth.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://colab.research.google.com/drive/15LFRMVOfEiF__FswVqTQstZC5ocC6Ur0?usp=sharing for cropping functions\n",
    "\n",
    "# Define the function that creates a bounding box and returns its min and max coordinates\n",
    "def bbox_side_len(point, side_len=10):\n",
    "    if point is None or point.is_empty:\n",
    "        return None, None, None, None  # Return None for all four values if the point is invalid\n",
    "    half_side = side_len / 2\n",
    "    minx, miny = point.x - half_side, point.y - half_side\n",
    "    maxx, maxy = point.x + half_side, point.y + half_side\n",
    "    return minx, miny, maxx, maxy\n",
    "\n",
    "def process_bbox(raster_path, bbox, output_dir, read_lock, write_lock, idx):\n",
    "    minx, miny, maxx, maxy = bbox\n",
    "    if minx is None:\n",
    "        return \"Invalid point\"\n",
    "\n",
    "    try:\n",
    "        with rio.open(raster_path) as src:\n",
    "            # Check if the bbox is within the raster bounds\n",
    "            raster_bounds = src.bounds\n",
    "            if (minx >= raster_bounds.right or maxx <= raster_bounds.left or\n",
    "                miny >= raster_bounds.top or maxy <= raster_bounds.bottom):\n",
    "                return \"Bounding box outside raster extent\"\n",
    "\n",
    "            window = src.window(minx, miny, maxx, maxy)\n",
    "\n",
    "            # Ensure the window has a valid size\n",
    "            if window.width < 1 or window.height < 1:\n",
    "                return \"Resulting window too small\"\n",
    "\n",
    "            with read_lock:\n",
    "                src_array = src.read(window=window)\n",
    "\n",
    "            # If the read array is empty, skip this bbox\n",
    "            if src_array.size == 0:\n",
    "                return \"Empty array read\"\n",
    "\n",
    "            profile = src.profile.copy()\n",
    "            profile.update({\n",
    "                \"height\": src_array.shape[1],\n",
    "                \"width\": src_array.shape[2],\n",
    "                \"transform\": rio.windows.transform(window, src.transform)\n",
    "            })\n",
    "\n",
    "            output_file = f\"{output_dir}/{idx}.tif\"  # Changed to use idx\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            with write_lock:\n",
    "                with rio.open(output_file, \"w\", **profile) as dst:\n",
    "                    dst.write(src_array)\n",
    "\n",
    "        return \"Success\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def do_tiling(raster_path, points_gdf, output_dir, num_workers=4, side_len=10):\n",
    "    # Create list of (bbox, idx) tuples\n",
    "    bbox_data = [(bbox_side_len(point, side_len=side_len), idx) \n",
    "                 for idx, point in zip(points_gdf.idx, points_gdf.geometry)]\n",
    "    valid_bbox_data = [(bbox, idx) for bbox, idx in bbox_data if bbox[0] is not None]\n",
    "\n",
    "    read_lock = threading.Lock()\n",
    "    write_lock = threading.Lock()\n",
    "\n",
    "    pbar = tqdm(total=len(valid_bbox_data), desc=\"Processing bounding boxes\", unit=\"bbox\")\n",
    "    errors = []\n",
    "\n",
    "    def process_and_update(bbox_info):\n",
    "        bbox, idx = bbox_info\n",
    "        result = process_bbox(raster_path, bbox, output_dir, read_lock, write_lock, idx)\n",
    "        pbar.update(1)\n",
    "        if result != \"Success\":\n",
    "            errors.append(result)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        list(executor.map(process_and_update, valid_bbox_data))\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nEncountered {len(errors)} errors:\")\n",
    "        for error in errors[:10]:  # Print first 10 errors\n",
    "            print(f\"  - {error}\")\n",
    "        if len(errors) > 10:\n",
    "            print(f\"  ... and {len(errors) - 10} more.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 cores\n"
     ]
    }
   ],
   "source": [
    "target_crop_sz_meters = 5 # how big to make crops in meters\n",
    "num_cores = os.cpu_count()\n",
    "print(f'Using {num_cores} cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster CRS: EPSG:32611\n",
      "GeoJSON CRS: EPSG:32611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bounding boxes: 100%|██████████| 884/884 [00:08<00:00, 107.56bbox/s]\n",
      "Processing bounding boxes: 100%|██████████| 716/716 [00:06<00:00, 106.85bbox/s]\n"
     ]
    },
    {
     "ename": "RasterioIOError",
     "evalue": "'../data/raster/geotiffs/.DS_Store' not recognized as being in a supported file format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mrasterio/_base.pyx:310\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_base.pyx:221\u001b[0m, in \u001b[0;36mrasterio._base.open_dataset\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mrasterio/_err.pyx:359\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: '../data/raster/geotiffs/.DS_Store' not recognized as being in a supported file format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Read and align CRS of raster and points\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeotiff\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[1;32m     12\u001b[0m     raster_crs \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mcrs\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaster CRS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraster_crs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/mpg-horses/lib/python3.13/site-packages/rasterio/env.py:463\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mpg-horses/lib/python3.13/site-packages/rasterio/__init__.py:356\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, opener, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     path \u001b[38;5;241m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 356\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    358\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[1;32m    359\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    360\u001b[0m     )\n",
      "File \u001b[0;32mrasterio/_base.pyx:312\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRasterioIOError\u001b[0m: '../data/raster/geotiffs/.DS_Store' not recognized as being in a supported file format."
     ]
    }
   ],
   "source": [
    "# Crop tiles for each geotiff\n",
    "for geotiff in geotiffs:\n",
    "    survey_name = os.path.basename(geotiff).split('.')[0].replace('-visible', '')\n",
    "    \n",
    "    # Set up output directories\n",
    "    output_base = f'../data/raster/tiles/{survey_name}'\n",
    "    for label in ['presence', 'absence']:\n",
    "        os.makedirs(f'{output_base}/{label}', exist_ok=True)\n",
    "\n",
    "    # Read and align CRS of raster and points\n",
    "    with rio.open(geotiff) as src:\n",
    "        raster_crs = src.crs\n",
    "        print(f\"Raster CRS: {raster_crs}\")\n",
    "\n",
    "    gdf = gpd.read_file(groundtruth)\n",
    "    print(f\"GeoJSON CRS: {gdf.crs}\")\n",
    "\n",
    "    if gdf.crs != raster_crs:\n",
    "        print(f\"Reprojecting from {gdf.crs} to {raster_crs}\")\n",
    "        gdf = gdf.to_crs(raster_crs)\n",
    "\n",
    "    # Process both presence and absence points\n",
    "    for presence_val in [1, 0]:\n",
    "        label = 'presence' if presence_val == 1 else 'absence'\n",
    "        points = gdf[gdf['Presence'] == presence_val]\n",
    "        output_dir = f'{output_base}/{label}'\n",
    "        \n",
    "        do_tiling(geotiff, points, output_dir,\n",
    "                 num_workers=num_cores, side_len=target_crop_sz_meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip -rq data/interim/tiles to tiles.zip\n",
    "# !zip -rq data/processed/tiles.zip data/tiles/mpg-horses_tiles.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpg-horses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
