{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see https://colab.research.google.com/drive/15LFRMVOfEiF__FswVqTQstZC5ocC6Ur0?usp=sharing for cropping functions, may require modification\n",
    "\n",
    "# for each drone_survey:\n",
    "#     for each row in ground truth:\n",
    "#         crop rgb_tile from drone_survey\n",
    "#         save tile to data/raster/tiles/drone_survey/idx.tif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve geotiff paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get survey array\n",
    "# Read the google sheet MPG Aerial Survey Manifest\n",
    "sheet = pd.read_csv(\n",
    "    \"https://docs.google.com/spreadsheets/d/e/2PACX-1vTgk2SSxgZ76UTYOlmf5UtjF1q59ZpKXCNH1Mn3rzbxQ_f6MvoTUirnUIKdcKxd-NIZk-MN8bsG3SP6/pub?output=csv\"\n",
    ")\n",
    "\n",
    "# filter by sensors 'RGB' and site 'Upper Partridge'\n",
    "upper_partridge = sheet[(sheet.sensor == \"RGB\") & (sheet.site == \"Upper Partridge\")]\n",
    "\n",
    "# Create array of cloud_storage paths from the orthomosaic column excluding nulls\n",
    "cloud_storage_paths = upper_partridge.orthomosaic.dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotiff_path = '../data/raster/geotiffs/240731_upperpartridge-visible.tif'\n",
    "geojson_path = '../data/vector/groundtruth.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that creates a bounding box and returns its min and max coordinates\n",
    "def bbox_side_len(point, side_len=10):\n",
    "    if point is None or point.is_empty:\n",
    "        return None, None, None, None  # Return None for all four values if the point is invalid\n",
    "    half_side = side_len / 2\n",
    "    minx, miny = point.x - half_side, point.y - half_side\n",
    "    maxx, maxy = point.x + half_side, point.y + half_side\n",
    "    return minx, miny, maxx, maxy\n",
    "\n",
    "def process_bbox(raster_path, bbox, output_dir, read_lock, write_lock, point_index):\n",
    "    minx, miny, maxx, maxy = bbox\n",
    "    if minx is None:\n",
    "        return \"Invalid point\"\n",
    "\n",
    "    try:\n",
    "        with rio.open(raster_path) as src:\n",
    "            # Check if the bbox is within the raster bounds\n",
    "            raster_bounds = src.bounds\n",
    "            if (minx >= raster_bounds.right or maxx <= raster_bounds.left or\n",
    "                miny >= raster_bounds.top or maxy <= raster_bounds.bottom):\n",
    "                return \"Bounding box outside raster extent\"\n",
    "\n",
    "            window = src.window(minx, miny, maxx, maxy)\n",
    "\n",
    "            # Ensure the window has a valid size\n",
    "            if window.width < 1 or window.height < 1:\n",
    "                return \"Resulting window too small\"\n",
    "\n",
    "            with read_lock:\n",
    "                src_array = src.read(window=window)\n",
    "\n",
    "            # If the read array is empty, skip this bbox\n",
    "            if src_array.size == 0:\n",
    "                return \"Empty array read\"\n",
    "\n",
    "            profile = src.profile.copy()\n",
    "            profile.update({\n",
    "                \"height\": src_array.shape[1],\n",
    "                \"width\": src_array.shape[2],\n",
    "                \"transform\": rio.windows.transform(window, src.transform)\n",
    "            })\n",
    "\n",
    "            output_file = f\"{output_dir}/{point_index}.tif\"  # Changed to use point_index\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            with write_lock:\n",
    "                with rio.open(output_file, \"w\", **profile) as dst:\n",
    "                    dst.write(src_array)\n",
    "\n",
    "        return \"Success\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def do_tiling(raster_path, points_gdf, output_dir, num_workers=4, side_len=10):\n",
    "    # Create list of (bbox, point_index) tuples\n",
    "    bbox_data = [(bbox_side_len(point, side_len=side_len), idx) \n",
    "                 for idx, point in zip(points_gdf.Point_Index, points_gdf.geometry)]\n",
    "    valid_bbox_data = [(bbox, idx) for bbox, idx in bbox_data if bbox[0] is not None]\n",
    "\n",
    "    read_lock = threading.Lock()\n",
    "    write_lock = threading.Lock()\n",
    "\n",
    "    pbar = tqdm(total=len(valid_bbox_data), desc=\"Processing bounding boxes\", unit=\"bbox\")\n",
    "    errors = []\n",
    "\n",
    "    def process_and_update(bbox_info):\n",
    "        bbox, point_index = bbox_info\n",
    "        result = process_bbox(raster_path, bbox, output_dir, read_lock, write_lock, point_index)\n",
    "        pbar.update(1)\n",
    "        if result != \"Success\":\n",
    "            errors.append(result)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        list(executor.map(process_and_update, valid_bbox_data))\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nEncountered {len(errors)} errors:\")\n",
    "        for error in errors[:10]:  # Print first 10 errors\n",
    "            print(f\"  - {error}\")\n",
    "        if len(errors) > 10:\n",
    "            print(f\"  ... and {len(errors) - 10} more.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crop_sz_meters = 5 # how big to make crops in meters\n",
    "num_cores = os.cpu_count()\n",
    "print(f'Using {num_cores} cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presence and Absence directories\n",
    "presence_dir = '../data/raster/tiles/presence'\n",
    "absence_dir = '../data/raster/tiles/absence'\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(presence_dir, exist_ok=True)\n",
    "os.makedirs(absence_dir, exist_ok=True)\n",
    "\n",
    "# Read the GeoJSON file\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Read the data and check CRS\n",
    "with rio.open(geotiff_path) as src:\n",
    "    raster_crs = src.crs\n",
    "    print(f\"Raster CRS: {raster_crs}\")\n",
    "\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "print(f\"GeoJSON CRS: {gdf.crs}\")\n",
    "\n",
    "# Reproject GeoJSON to match raster if needed\n",
    "if gdf.crs != raster_crs:\n",
    "    print(f\"Reprojecting from {gdf.crs} to {raster_crs}\")\n",
    "    gdf = gdf.to_crs(raster_crs)\n",
    "    \n",
    "# Filter for presence points (presence == 1)\n",
    "presence_points = gdf[gdf['Presence'] == 1]\n",
    "# Filter for absence points (presence == 0)\n",
    "absence_points = gdf[gdf['Presence'] == 0]\n",
    "\n",
    "# Process presence points\n",
    "do_tiling(geotiff_path, presence_points, presence_dir, \n",
    "          num_workers=num_cores, side_len=target_crop_sz_meters)\n",
    "\n",
    "# Process absence points\n",
    "do_tiling(geotiff_path, absence_points, absence_dir, \n",
    "          num_workers=num_cores, side_len=target_crop_sz_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf Presence unique values\n",
    "print(f\"Presence unique values: {gdf['Presence'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip -rq data/interim/tiles to tiles.zip\n",
    "!zip -rq data/processed/tiles.zip data/interim/tiles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpg-horses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
