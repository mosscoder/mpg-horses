{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals\n",
    "\n",
    "This notebook covers the fundamentals of working with PyTorch for deep learning, including:\n",
    "- Loading data from Hugging Face\n",
    "- Applying proper transformations and normalization\n",
    "- Using pre-trained models (ResNet50)\n",
    "- Setting up training with appropriate optimization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for or install all necessary packages with conda from environment.yml\n",
    "%conda env update -f environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset from Hugging Face\n",
    "dataset = load_dataset(\"cifar10\")\n",
    "\n",
    "# View dataset structure\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Transformations\n",
    "\n",
    "Data normalization is **critical** for model performance. We use ImageNet statistics for normalization since we'll be using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for training data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # Resize and crop\n",
    "    transforms.RandomHorizontalFlip(),  # Horizontal flip with 50% probability\n",
    "    transforms.RandomRotation(15),      # Random rotation up to 15 degrees\n",
    "    transforms.ToTensor(),              # Convert to tensor\n",
    "    transforms.Normalize(               # Normalize with ImageNet stats\n",
    "        mean=[0.485, 0.456, 0.406],     # RGB means from ImageNet\n",
    "        std=[0.229, 0.224, 0.225]       # RGB standard deviations from ImageNet\n",
    "    )\n",
    "])\n",
    "\n",
    "# Validation transformations (no augmentation, only resize and normalize)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Transformations to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply transformations to the training dataset\n",
    "def transform_train_dataset(examples):\n",
    "    examples[\"pixel_values\"] = [train_transforms(image.convert(\"RGB\")) for image in examples[\"img\"]]\n",
    "    return examples\n",
    "\n",
    "# Function to apply transformations to the validation dataset\n",
    "def transform_val_dataset(examples):\n",
    "    examples[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in examples[\"img\"]]\n",
    "    return examples\n",
    "\n",
    "# Apply transformations to training set\n",
    "transformed_train_dataset = dataset[\"train\"].map(\n",
    "    transform_train_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=[\"img\"]  # Remove original images after transformation\n",
    ")\n",
    "\n",
    "# Apply transformations to test set\n",
    "transformed_val_dataset = dataset[\"test\"].map(\n",
    "    transform_val_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=[\"img\"]\n",
    ")\n",
    "\n",
    "# Set the format for PyTorch\n",
    "transformed_train_dataset.set_format(type=\"torch\", columns=[\"pixel_values\", \"label\"])\n",
    "transformed_val_dataset.set_format(type=\"torch\", columns=[\"pixel_values\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "    transformed_train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    transformed_val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a Batch\n",
    "\n",
    "Let's visualize some images from our dataloader to verify transformations are applied correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to denormalize images for visualization\n",
    "def denormalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "# Get a batch from the dataloader\n",
    "images, labels = next(iter(train_dataloader))\n",
    "\n",
    "# Visualize a few images from the batch\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(images):\n",
    "        # Denormalize the image\n",
    "        img = denormalize(images[i])\n",
    "        img = img.permute(1, 2, 0).numpy()  # Change from CxHxW to HxWxC\n",
    "        img = np.clip(img, 0, 1)  # Clip values to valid range\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Label: {labels[i].item()}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture with ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the final fully connected layer for our task\n",
    "# For CIFAR-10, we have 10 classes\n",
    "num_classes = 10\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Print model architecture summary\n",
    "print(f\"Model: ResNet50\")\n",
    "print(f\"Number of trainable parameters: {sum(p.numel() for p in model.fc.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "We'll use default settings for the optimizer and only tune the learning rate and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer with default settings\n",
    "# Only optimize the parameters of the new head (model.fc)\n",
    "learning_rate = 0.001  # This is one of the few hyperparameters we'll tune\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
    "\n",
    "# Number of epochs is another parameter we'll tune\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_acc = 100. * correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_loss = val_running_loss / len(val_dataloader)\n",
    "    val_acc = 100. * correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation metrics\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "ax1.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "ax1.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot accuracy\n",
    "ax2.plot(range(1, num_epochs+1), train_accs, label='Train Accuracy')\n",
    "ax2.plot(range(1, num_epochs+1), val_accs, label='Validation Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate accuracy for each class\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print(f'Overall Accuracy on the test set: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Print accuracy for each class\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "for i in range(10):\n",
    "    print(f'Accuracy of {classes[i]}: {100 * class_correct[i] / class_total[i]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points to Remember\n",
    "\n",
    "1. **Data Normalization is Critical**\n",
    "   - Always normalize your input data using mean and standard deviation\n",
    "   - For transfer learning with pre-trained models, use the same normalization values that were used during pre-training (e.g., ImageNet stats)\n",
    "\n",
    "2. **Data Transformations**\n",
    "   - Apply appropriate augmentations for training data (flips, rotations, crops)\n",
    "   - Use only resizing and normalization for validation/test data\n",
    "   - Transformations help prevent overfitting and improve model generalization\n",
    "\n",
    "3. **Model Architecture**\n",
    "   - Start with a pre-trained model like ResNet50\n",
    "   - Modify only the final layer (head) to match your specific task\n",
    "   - Freeze pre-trained layers initially to leverage transfer learning\n",
    "\n",
    "4. **Optimization Settings**\n",
    "   - Start with default optimizer settings\n",
    "   - Focus on tuning learning rate and number of epochs first\n",
    "   - Monitor validation metrics to prevent overfitting\n",
    "\n",
    "5. **Progressive Unfreezing**\n",
    "   - After initial training, you can unfreeze more layers gradually\n",
    "   - Use a smaller learning rate when fine-tuning pre-trained layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Hyperparameter Tuning**\n",
    "   - Try different learning rates\n",
    "   - Experiment with different batch sizes\n",
    "   - Test different optimizers (SGD with momentum, AdamW)\n",
    "\n",
    "2. **Model Improvements**\n",
    "   - Unfreeze more layers for fine-tuning\n",
    "   - Try different pre-trained architectures (EfficientNet, ViT)\n",
    "   - Implement learning rate scheduling\n",
    "\n",
    "3. **Advanced Techniques**\n",
    "   - Implement data augmentation strategies like mixup or cutmix\n",
    "   - Try different loss functions\n",
    "   - Implement ensemble methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpg-horses",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
